{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3207388-a69c-462a-94f5-268ca0cd78e0",
   "metadata": {},
   "source": [
    "# Predicting Machine Failure Type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c0765ff-490e-4144-b1ee-871ef5aa07e7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, classification_report, precision_recall_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import shap\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "645259be-5678-4471-9970-3836f0ed0242",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load the preprocessed data\n",
    "data = pd.read_csv('Preprocessed_Data.csv')\n",
    "\n",
    "# Rename columns to remove special characters\n",
    "data.rename(columns={\n",
    "    'Air temperature [K]': 'Air_temperature_K',\n",
    "    'Process temperature [K]': 'Process_temperature_K',\n",
    "    'Rotational speed [rpm]': 'Rotational_speed_rpm',\n",
    "    'Torque [Nm]': 'Torque_Nm',\n",
    "    'Tool wear [min]': 'Tool_wear_min'\n",
    "}, inplace=True)\n",
    "\n",
    "# Create the 'No failure' column\n",
    "data['No failure'] = 1 - data['Machine failure']\n",
    "\n",
    "# Define features and target\n",
    "X = data[['Type', 'Air_temperature_K', 'Process_temperature_K', 'Rotational_speed_rpm', 'Torque_Nm', 'Tool_wear_min']]\n",
    "y = data[['No failure', 'TWF', 'HDF', 'PWF', 'OSF', 'RNF']].idxmax(axis=1)\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f1e610d-a4ab-41f8-9f89-ca01b230743e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Initialize stratified split\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y_encoded):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "\n",
    "# Apply SMOTE to oversample the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define all possible target names\n",
    "all_classes = label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "537b9530-c52c-491d-a891-953b9ebb4494",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define models with default parameters\n",
    "default_models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42),\n",
    "    'Neural Network': MLPClassifier(random_state=42, max_iter=300)\n",
    "}\n",
    "\n",
    "# Train and evaluate default models\n",
    "default_trained_models = {}\n",
    "default_y_preds = {}\n",
    "default_y_probas = {}\n",
    "\n",
    "for name, model in default_models.items():\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    default_y_preds[name] = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        default_y_probas[name] = model.predict_proba(X_test)\n",
    "    default_trained_models[name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a2f4b79-0fd3-4f7e-b388-1538b0af5a97",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'max_depth': 35, 'min_samples_split': 3, 'n_estimators': 150}\n",
      "Best parameters for XGBoost: {'learning_rate': 0.4, 'max_depth': 5, 'n_estimators': 250, 'subsample': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/oussama/anaconda3/envs/notebook/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Neural Network: {'activation': 'relu', 'hidden_layer_sizes': (50, 50), 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for best parameters\n",
    "refined_param_grids = {\n",
    "    'Random Forest': {\n",
    "        'max_depth': [35,40],\n",
    "        'min_samples_split': [2, 3, 4],\n",
    "        'n_estimators': [100, 150, 200]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'learning_rate': [0.25, 0.3, 0.4],\n",
    "        'max_depth': [4, 5, 6],\n",
    "        'n_estimators': [250,300,350],\n",
    "        'subsample': [0.9, 1.0]\n",
    "    },\n",
    "    'Neural Network': {\n",
    "        'activation': ['tanh', 'relu'],\n",
    "        'hidden_layer_sizes': [(50, 50), (100,)],\n",
    "        'solver': ['adam', 'sgd']\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "for name, model in default_models.items():\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=refined_param_grids[name], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train_res, y_train_res)\n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06a27c82-df2d-4ce3-b73d-9d7f0986d745",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Train and evaluate best models\n",
    "best_trained_models = {}\n",
    "best_y_preds = {}\n",
    "best_y_probas = {}\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    best_y_preds[name] = model.predict(X_test)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        best_y_probas[name] = model.predict_proba(X_test)\n",
    "    best_trained_models[name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2811feb4-ad56-4ff7-96ea-26a963a85df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aebbf53ddd84961a5e9c5172b8a970e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Model:', options=('Random Forest', 'XGBoost', 'Neural Network'), v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.display_plots(model_name, plot_type, model_type)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot functions\n",
    "def plot_confusion_matrix(y_test, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=all_classes, yticklabels=all_classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve(y_test, y_proba, model_name):\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    for i in range(len(all_classes)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test == i, y_proba[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        plt.plot(fpr[i], tpr[i], lw=2, label=f'Class {all_classes[i]} (area = {roc_auc[i]:0.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver Operating Characteristic - {model_name}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_precision_recall_curve(y_test, y_proba, model_name):\n",
    "    precision = {}\n",
    "    recall = {}\n",
    "    pr_auc = {}\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    for i in range(len(all_classes)):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(y_test == i, y_proba[:, i])\n",
    "        pr_auc[i] = auc(recall[i], precision[i])\n",
    "        plt.plot(recall[i], precision[i], lw=2, label=f'Class {all_classes[i]} (area = {pr_auc[i]:0.2f})')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - {model_name}')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_metrics(y_test, y_pred, model_name):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    metrics = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1}\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    bars = plt.bar(metrics.keys(), metrics.values(), color='blue')\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Scores')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.title(f'Metrics - {model_name}')\n",
    "    \n",
    "    # Annotate bars with the metric values\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), va='bottom')  # va: vertical alignment\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Dropdown Menu Function\n",
    "def display_plots(model_name, plot_type, model_type):\n",
    "    if model_type == 'Default':\n",
    "        y_pred = default_y_preds[model_name]\n",
    "        y_proba = default_y_probas[model_name]\n",
    "    elif model_type == 'Best':\n",
    "        y_pred = best_y_preds[model_name]\n",
    "        y_proba = best_y_probas[model_name]\n",
    "    \n",
    "    if plot_type == 'Confusion Matrix':\n",
    "        plot_confusion_matrix(y_test, y_pred, f\"{model_name} ({model_type})\")\n",
    "    elif plot_type == 'ROC Curve':\n",
    "        plot_roc_curve(y_test, y_proba, f\"{model_name} ({model_type})\")\n",
    "    elif plot_type == 'Precision-Recall Curve':\n",
    "        plot_precision_recall_curve(y_test, y_proba, f\"{model_name} ({model_type})\")\n",
    "    elif plot_type == 'Metrics':\n",
    "        plot_metrics(y_test, y_pred, f\"{model_name} ({model_type})\")\n",
    "\n",
    "# Create Dropdown Widgets\n",
    "model_dropdown = widgets.Dropdown(options=list(default_models.keys()), description='Model:')\n",
    "plot_dropdown = widgets.Dropdown(options=['Confusion Matrix', 'ROC Curve', 'Precision-Recall Curve', 'Metrics'], description='Plot Type:')\n",
    "model_type_dropdown = widgets.Dropdown(options=['Default', 'Best'], description='Model Type:')\n",
    "\n",
    "# Display Interactive Widgets\n",
    "interact(display_plots, model_name=model_dropdown, plot_type=plot_dropdown, model_type=model_type_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d6bf18-8f04-48e6-b657-574a3c867d98",
   "metadata": {},
   "source": [
    "# Model Explanation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57cff6f2-02bc-4361-a4ae-021aada3b97d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Initialize TreeExplainer for Random Forest and XGBoost\n",
    "rf_explainer = shap.TreeExplainer(best_models['Random Forest'], X_train_res)\n",
    "xgb_explainer = shap.TreeExplainer(best_models['XGBoost'], X_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4e84aa5-48f2-4f52-8184-2ba1915cbe1a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 169177/169225 [51:32<00:00]        "
     ]
    }
   ],
   "source": [
    "# Compute SHAP values for training data\n",
    "rf_shap_values = rf_explainer.shap_values(X_train_res, check_additivity=False)\n",
    "xgb_shap_values = xgb_explainer.shap_values(X_train_res, check_additivity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7776fe3-cf3b-4992-9025-cf462aadc167",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33845, 6, 5)\n",
      "(33845, 6, 5)\n"
     ]
    }
   ],
   "source": [
    "print(rf_shap_values.shape)\n",
    "print(xgb_shap_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bc88326-e08d-45b3-83e1-af47548d0691",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# List of feature names\n",
    "features = X_train_res.columns.tolist()\n",
    "all_classes = label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "30ce17f2-4c19-4369-9e92-9ce26b8fed27",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to plot SHAP summary plots for multi-class classification\n",
    "def plot_shap_summary_multiclass(model_name, class_name):\n",
    "    plt.figure()\n",
    "    class_index = list(all_classes).index(class_name)\n",
    "    if model_name == 'Random Forest':\n",
    "        shap.summary_plot(rf_shap_values[:,:,class_index], X_train_res, feature_names=features)\n",
    "    elif model_name == 'XGBoost':\n",
    "        shap.summary_plot(xgb_shap_values[:,:,class_index], X_train_res, feature_names=features)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a963ff9-ff1b-41f8-88b3-f50e6385af17",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to plot SHAP dependence plots for multi-class classification\n",
    "def plot_shap_dependence_multiclass(model_name, interaction_feature, class_name):\n",
    "    # Define the number of columns for the grid\n",
    "    n_cols = 3\n",
    "    n_rows = (len(features) + n_cols - 1) // n_cols  # Compute the number of rows needed\n",
    "    class_index = list(all_classes).index(class_name)\n",
    "\n",
    "    # Plot SHAP dependence plots for the selected model\n",
    "    if model_name == 'Random Forest':\n",
    "        shap_values = rf_shap_values[:,:,class_index]  # Use SHAP values for the selected class\n",
    "    elif model_name == 'XGBoost':\n",
    "        shap_values = xgb_shap_values[:,:,class_index]  # Use SHAP values for the selected class\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 5))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        shap.dependence_plot(feature, shap_values, X_train_res, interaction_index=interaction_feature if interaction_feature != 'auto' else None, ax=axes[i], show=False)\n",
    "        axes[i].set_title(f'{model_name} SHAP Dependence for {feature} (Class {class_name})')\n",
    "\n",
    "    # Remove any empty subplots\n",
    "    for j in range(i + 1, n_rows * n_cols):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ccfd2bd-3e2b-499d-b9e8-e7f32d4b36dc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create dropdown widgets\n",
    "model_dropdown = widgets.Dropdown(options=['Random Forest', 'XGBoost'], description='Model:')\n",
    "class_dropdown = widgets.Dropdown(options=list(all_classes), description='Class:')\n",
    "interaction_feature_dropdown = widgets.Dropdown(options=['auto'] + features, description='Interact:')\n",
    "\n",
    "# Interactive function to update SHAP summary plots based on dropdown selection\n",
    "def update_shap_summary(model_name, class_name):\n",
    "    plot_shap_summary_multiclass(model_name, class_name)\n",
    "\n",
    "# Interactive function to update SHAP dependence plots based on dropdown selection\n",
    "def update_shap_dependence(model_name, interaction_feature, class_name):\n",
    "    plot_shap_dependence_multiclass(model_name, interaction_feature, class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13fe38fc-0b34-4897-912a-09ffc3c4bd56",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2dff25a64748d5ae4c6e4984b9f15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Model:', options=('Random Forest', 'XGBoost'), value='Random Fores…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update_shap_summary(model_name, class_name)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display interactive widgets for SHAP summary plots\n",
    "interact(update_shap_summary, model_name=model_dropdown, class_name=class_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8dfef4f-5f6d-4839-b2b5-315aae642630",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188e0ade81174317b972a503c7ef1d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Model:', index=1, options=('Random Forest', 'XGBoost'), value='XGB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update_shap_dependence(model_name, interaction_feature, class_name)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display interactive widgets for SHAP dependence plots\n",
    "interact(update_shap_dependence, model_name=model_dropdown, interaction_feature=interaction_feature_dropdown, class_name=class_dropdown)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
